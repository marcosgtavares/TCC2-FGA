{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39400327-13f4-46b9-9ad5-2d8f6c8a8434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 06:37:16.540177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 06:37:16.540232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 06:37:16.541150: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 06:37:16.547441: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 06:37:17.698121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten,Bidirectional,GRU,LSTM,SpatialDropout1D,Reshape\n",
    "from tensorflow.keras.layers import Embedding,concatenate\n",
    "from tensorflow.keras.layers import Conv2D, GlobalMaxPooling2D,MaxPool2D,MaxPool3D,GlobalAveragePooling2D,Conv3D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e746e08d-ef31-4e76-a5ae-92274ab91adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/910081559684675444', creation_time=1716953811123, experiment_id='910081559684675444', last_update_time=1716953811123, lifecycle_stage='active', name='FAKE_LSTM', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import optuna\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "def get_or_create_experiment(experiment_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "    This function checks if an experiment with the given name exists within MLflow.\n",
    "    If it does, the function returns its ID. If not, it creates a new experiment\n",
    "    with the provided name and returns its ID.\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "    - str: ID of the existing or newly created MLflow experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)\n",
    "experiment_id = get_or_create_experiment(\"FAKE_LSTM\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53594c2c-38c8-4cef-b168-b761af6ec5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def champion_callback(study, frozen_trial):\n",
    "    \"\"\"\n",
    "    Logging callback that will report when a new trial iteration improves upon existing\n",
    "    best trial values.\n",
    "\n",
    "    Note: This callback is not intended for use in distributed computing systems such as Spark\n",
    "    or Ray due to the micro-batch iterative implementation for distributing trials to a cluster's\n",
    "    workers or agents.\n",
    "    The race conditions with file system state management for distributed trials will render\n",
    "    inconsistent values with this callback.\n",
    "    \"\"\"\n",
    "\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081598bd-96f9-4aeb-8388-96e079a77efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([pd.read_csv(\"fake_train_balanced_indexed.csv\"), pd.read_csv(\"fake_train_full_paraphrased_aug_indexed_balanced_llama3.csv\"), pd.read_csv(\"fake_train_inc_full_backtranslated_aug_indexed_balanced_v1.csv\")]).reset_index()\n",
    "# pd.read_csv(\"fake_train_inc_full_backtranslated_aug_indexed_balanced_v1.csv\"), pd.read_csv(\"fake_train_full_paraphrased_aug_indexed_balanced_llama3.csv\")\n",
    "validate = pd.read_csv(\"fake_validate_balanced_indexed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf60a47-6fed-4d03-acff-d9a156393dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "train['tokens']=train['text'].apply(lambda x: word_tokenize(x, language='portuguese'))\n",
    "validate['tokens']=validate['text'].apply(lambda x: word_tokenize(x, language='portuguese'))\n",
    "all_training_words = set([word for tokens in list(train[\"tokens\"].values) for word in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cb6315-3e0b-47ae-ab09-ac250dfe538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with open(\"cbow_s300.txt\", \"r\") as f: #skip_s300.txt cbow_s300.txt\n",
    "    for line in f:\n",
    "        token_emb = line.rstrip().split(\" \")\n",
    "        embedding = token_emb[-300:]\n",
    "        token = \" \".join(token_emb[:-300])\n",
    "        if token in all_training_words:\n",
    "            token_dict[token] = embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43e60de-6791-4cc5-8457-305ad3826c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "T_VOCAB = sorted(list(all_training_words))\n",
    "tokenizer = Tokenizer(num_words=len(T_VOCAB), char_level=False)\n",
    "tokenizer.fit_on_texts(list(train[\"tokens\"].values))\n",
    "train_word_index = tokenizer.word_index\n",
    "len(train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab228caa-0af9-427d-b7e0-61ca41a2d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_weights = np.zeros((len(train_word_index)+1, 300))\n",
    "for word, i in train_word_index.items():\n",
    "    embedding_vector = token_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        train_embedding_weights[int(i)] = [float(embedding) for embedding in embedding_vector]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3471cb1a-2a6c-43b9-8868-66e576b8aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data \n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/PY3/portuguese.pickle')\n",
    "\n",
    "train['sentence_token']=train['text'].apply(lambda x: sent_tokenizer.tokenize(x))\n",
    "train['train_seq']=train['sentence_token'].apply(lambda x:tokenizer.texts_to_sequences(x))\n",
    "\n",
    "validate['sentence_token']=validate['text'].apply(lambda x: sent_tokenizer.tokenize(x))\n",
    "validate['train_seq']=validate['sentence_token'].apply(lambda x:tokenizer.texts_to_sequences(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81751f0-0c13-4cf1-a2d3-3705f620e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "train['train_token']= train['train_seq'].apply(lambda x: list(itertools.chain.from_iterable(x)))\n",
    "validate['train_token']=validate['train_seq'].apply(lambda x: list(itertools.chain.from_iterable(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd62abb-5517-41ef-b1f8-644ec159d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
    "embed_size=300\n",
    "embedding_matrix=train_embedding_weights\n",
    "max_features=len(train_word_index) + 1\n",
    "import tensorflow\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "def get_model(learning_rate, epsilon, maxlen):\n",
    "    optimizer = tensorflow.keras.optimizers.Adam(learning_rate=learning_rate, epsilon = epsilon)\n",
    "    loss = tensorflow.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    input = Input(shape=(maxlen, ))\n",
    "    model = tensorflow.keras.Sequential([\n",
    "        input,\n",
    "        tensorflow.keras.layers.Embedding(max_features, embed_size, weights=[embedding_matrix], mask_zero=True),\n",
    "        tensorflow.keras.layers.Bidirectional(tensorflow.keras.layers.LSTM(embed_size,  return_sequences=True)),\n",
    "        tensorflow.keras.layers.Bidirectional(tensorflow.keras.layers.LSTM(int(embed_size/2))),\n",
    "        tensorflow.keras.layers.Dense(embed_size, activation='relu'),\n",
    "        tensorflow.keras.layers.Dropout(0.5),\n",
    "        tensorflow.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\", Precision(), Recall()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f19058-ed41-4758-a78e-1b84f6f34d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import gc\n",
    "from numba import cuda \n",
    "import sys\n",
    "from multiprocessing import Queue, Process\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from typing import Optional\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "class HEnconde(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        json.JSONEncoder.default(self, obj)\n",
    "class TFKerasPruningCallback(TFKerasPruningCallback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # Allow instances to be re-used\n",
    "        self.best_weights = None\n",
    "        self.best_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch: int, logs: Optional[Dict[str, Any]] = None) -> None:\n",
    "        logs = logs or {}\n",
    "        current_score = logs.get(self._monitor)\n",
    "        if float(self.best_acc) < float(current_score):\n",
    "            self.best_acc = current_score\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        if current_score is None:\n",
    "            message = (\n",
    "                \"The metric '{}' is not in the evaluation logs for pruning. \"\n",
    "                \"Please make sure you set the correct metric name.\".format(self._monitor)\n",
    "            )\n",
    "            warnings.warn(message)\n",
    "            return\n",
    "\n",
    "        # Report current score and epoch to Optuna's trial.\n",
    "        self._trial.report(float(current_score), step=epoch)\n",
    "\n",
    "        # Prune trial if needed\n",
    "        if self._trial.should_prune():\n",
    "            message = \"Trial was pruned at epoch {}.\".format(epoch)\n",
    "            self.model.stop_training = True\n",
    "            #raise optuna.TrialPruned(message)\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "    \n",
    "def train_model(params, callbacks):\n",
    "    def pad_split(x):\n",
    "            x += ((params[\"maxlen\"] - len(x)) if len(x)<params[\"maxlen\"] else 0) * [0]    \n",
    "            return x[:params[\"maxlen\"]]\n",
    "    train_lstm = train['train_token'].apply(lambda x: pad_split(x))\n",
    "    validate_lstm = validate['train_token'].apply(lambda x: pad_split(x))\n",
    "    \n",
    "    model = get_model(params[\"learning_rate\"], params[\"epsilon\"], params[\"maxlen\"])\n",
    "    tf.keras.utils.set_random_seed(5113)\n",
    "    history=model.fit(list(train_lstm.values), [float(x) for x in train[\"misinformation\"].values],validation_data=(list(validate_lstm.values), [float(x) for x in validate[\"misinformation\"].values]), epochs=params[\"epochs\"],batch_size=params[\"batch_size\"],verbose=0,callbacks = callbacks,)\n",
    "    #metrics=model.evaluate(list(validate_cnn.values), [float(x) for x in validate[\"misinformation\"].values], verbose=0)\n",
    "    best_acc_i = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "    metrics = []\n",
    "    for metric_name in model.metrics_names:\n",
    "        metrics.append(history.history[\"val_\" + metric_name][best_acc_i])\n",
    "    for best_m in glob.glob(\"best_lstm_*.h5\"):\n",
    "        if float(best_m[:-3].replace(\"best_lstm_\", \"\")) < float(history.history['val_accuracy'][best_acc_i]):\n",
    "            model.save_weights(f\"best_lstm_{str(history.history['val_accuracy'][best_acc_i])}.h5\")\n",
    "            os.remove(best_m)\n",
    "            with open(f\"best_lstm_history.json\", \"w\")as f:\n",
    "                f.write(json.dumps(dict(history.history), indent=4, cls=HEnconde))\n",
    "    return [best_acc_i, zip(model.metrics_names, metrics)]\n",
    "\n",
    "#https://stackoverflow.com/questions/39758094/clearing-tensorflow-gpu-memory-after-model-execution\n",
    "def process_run(func, params, callbacks):\n",
    "    def wrapper_func(queue, params, callbacks):\n",
    "        try:\n",
    "            result = func(params, callbacks)\n",
    "            error = None\n",
    "        except Exception:\n",
    "            result = None\n",
    "            ex_type, ex_value, tb = sys.exc_info()\n",
    "            error = ex_type, ex_value\n",
    "        queue.put((result, error))\n",
    "\n",
    "    def process(params, callbacks):\n",
    "        queue = Queue()\n",
    "        p = Process(target = wrapper_func, args = [queue] + [params] + [callbacks])\n",
    "        p.start()\n",
    "        result, error = queue.get()\n",
    "        p.join()\n",
    "        return result, error  \n",
    "\n",
    "    result, error = process(params, callbacks)\n",
    "    return result, error\n",
    "\n",
    "\n",
    "def objective(trial, study):\n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-2),\n",
    "        \"epsilon\": trial.suggest_float(\"epsilon\", 1e-8, 1e-5),\n",
    "        \"maxlen\": trial.suggest_int(\"maxlen\", 64, 512, step=64),\n",
    "        \"epochs\": 20, #trial.suggest_int(\"epochs\", 2, 12, step=2)\n",
    "        \"batch_size\":trial.suggest_int(\"batch_size\", 16, 64, step=8)\n",
    "    }\n",
    "    callbacks = [TFKerasPruningCallback(trial, \"val_accuracy\"), tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=2, verbose=0, mode=\"max\", restore_best_weights=True)]\n",
    "    #TFKerasPruningCallback(trial, \"val_accuracy\")\n",
    "    #tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3, verbose=0, mode=\"max\"), \n",
    "    with mlflow.start_run(nested=True, run_name=f\"LSTM_MODEL_PARA_AUG_CBOW_lr_{params['learning_rate']}_eps_{params['epsilon']}_maxlen_{params['maxlen']}_epochs_{params['epochs']}_bs_{params['batch_size']}\"):\n",
    "        metrics, error = process_run(train_model, params=params, callbacks=callbacks)\n",
    "        print(error)\n",
    "        #metrics = train_model(params, callbacks)\n",
    "        # Log to MLflow\n",
    "        params[\"epochs\"] = metrics[0] + 1\n",
    "        mlflow.log_params(params)\n",
    "        metrics = list(metrics[1])\n",
    "        metrics = dict(metrics)\n",
    "        metrics[\"f1_score\"] = 2 * (metrics[\"precision\"] * metrics[\"recall\"]) / (metrics[\"precision\"] + metrics[\"recall\"]) if metrics[\"precision\"] + metrics[\"recall\"] != 0 else 0\n",
    "        for metric in metrics:\n",
    "            mlflow.log_metric(metric, metrics[metric])\n",
    "        print(dict(metrics))\n",
    "    return metrics[\"accuracy\"]\n",
    "        #best_acc = []\n",
    "        #for i in range(params[\"epochs\"]):\n",
    "        #    best_acc.append(i, trial.intermediate_values[i])\n",
    "        #best_acc = max(best_acc, key = lambda x: x[1])\n",
    "        #params[\"epochs\"] = best_acc[0] + 1\n",
    "        #mlflow.log_params(params)\n",
    "        #if not metrics and best_acc <= best_value:\n",
    "        #    print(params, error)\n",
    "        #    raise optuna.TrialPruned()\n",
    "        #mlflow.log_metric(\"accuracy\", best_acc)\n",
    "    #return best_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a02639-e2d0-4abf-a1f1-bfbf7fc967d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markt/tcc/jupyter/jupyter-ml/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2024-06-09 15:35:38,160] A new study created in RDB with name: LSTM_MODEL_PARA_AUG_CBOW_V10\n",
      "2024-06-09 15:35:38.792007: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:38.888258: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:38.888363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:38.896116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:38.896242: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:38.896290: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:39.134200: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:39.134327: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:39.134346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 15:35:39.134417: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:35:39.134443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 15:35:39.559038: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 254731200 exceeds 10% of free system memory.\n",
      "2024-06-09 15:36:15.218076: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 15:36:15.691629: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 15:36:17.084042: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f69c9081070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 15:36:17.084082: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 15:36:17.089670: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717958177.158579   25391 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-09 15:38:14.334643: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 254731200 exceeds 10% of free system memory.\n",
      "2024-06-09 15:38:14.558131: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 254731200 exceeds 10% of free system memory.\n",
      "2024-06-09 15:38:14.762245: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 254731200 exceeds 10% of free system memory.\n",
      "2024-06-09 15:41:15.451614: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 254731200 exceeds 10% of free system memory.\n",
      "[I 2024-06-09 15:44:17,475] Trial 0 finished with value: 0.7767220735549927 and parameters: {'learning_rate': 0.0007127764615427488, 'epsilon': 9.625274247076414e-06, 'maxlen': 448, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.9942963123321533, 'accuracy': 0.7767220735549927, 'precision': 0.7612107396125793, 'recall': 0.8064132928848267, 'f1_score': 0.7831603067890454}\n",
      "Initial trial 0 achieved value: 0.7767220735549927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:44:17.912815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:17.987299: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:17.987394: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:17.992832: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:17.992943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:17.992988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:18.157680: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:18.157813: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:18.157835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 15:44:18.157897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:44:18.157941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 15:44:44.454829: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 15:44:44.940466: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 15:44:46.338375: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8c0e0080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 15:44:46.338415: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 15:44:46.344458: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717958686.412830   30627 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 15:50:17,834] Trial 1 finished with value: 0.764845609664917 and parameters: {'learning_rate': 0.0020180357921904288, 'epsilon': 3.291178107687719e-06, 'maxlen': 256, 'batch_size': 40}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.386279582977295, 'accuracy': 0.764845609664917, 'precision': 0.7477777600288391, 'recall': 0.7992874383926392, 'f1_score': 0.7726750894665314}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:50:18.263760: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.341114: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.341218: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.345757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.345863: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.345909: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.553116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.553300: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.553326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 15:50:18.553392: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:50:18.553427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 15:50:41.481831: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 15:50:41.929552: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 15:50:43.230862: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7898a270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 15:50:43.230901: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 15:50:43.236314: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717959043.304937    3960 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 15:58:22,584] Trial 2 finished with value: 0.7505938410758972 and parameters: {'learning_rate': 0.0020870288799884644, 'epsilon': 6.617599410191877e-06, 'maxlen': 192, 'batch_size': 24}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.8919460773468018, 'accuracy': 0.7505938410758972, 'precision': 0.75, 'recall': 0.7517814636230469, 'f1_score': 0.7508896751955253}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:58:23.092130: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.167132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.167230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.172063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.172177: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.172224: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.353024: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.353164: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.353187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 15:58:23.353253: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 15:58:23.353304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 15:58:55.948619: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 15:58:56.394146: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 15:58:57.727431: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a73353ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 15:58:57.727471: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 15:58:57.732984: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717959537.800813   10357 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:08:07,635] Trial 3 finished with value: 0.7678147554397583 and parameters: {'learning_rate': 0.004529586757561775, 'epsilon': 7.946367319088757e-06, 'maxlen': 384, 'batch_size': 48}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.1126116514205933, 'accuracy': 0.7678147554397583, 'precision': 0.7416934370994568, 'recall': 0.8218527436256409, 'f1_score': 0.7797183015427588}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:08:08.178414: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.251615: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.251728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.256185: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.256285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.256330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.431835: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.431971: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.431988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:08:08.432050: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:08:08.432081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:08:40.985570: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:08:41.444282: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:08:42.776825: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8650b8d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:08:42.776868: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:08:42.782427: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717960122.852457   16386 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:16:01,444] Trial 4 finished with value: 0.7725653052330017 and parameters: {'learning_rate': 0.00698523431608605, 'epsilon': 3.423782867357634e-06, 'maxlen': 384, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.3215678930282593, 'accuracy': 0.7725653052330017, 'precision': 0.77224200963974, 'recall': 0.7731591463088989, 'f1_score': 0.7727003058314954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:16:02.021605: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.098977: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.099080: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.105435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.105568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.105616: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.281372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.281500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.281518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:16:02.281579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:16:02.281605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:16:42.682200: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:16:43.138481: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:16:44.409124: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a800a68d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:16:44.409163: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:16:44.414773: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717960604.483040   21665 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:23:53,107] Trial 5 finished with value: 0.7743467688560486 and parameters: {'learning_rate': 0.0034571666409786944, 'epsilon': 5.282736511586462e-07, 'maxlen': 512, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.9307059049606323, 'accuracy': 0.7743467688560486, 'precision': 0.7692307829856873, 'recall': 0.783847987651825, 'f1_score': 0.7764705985075875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:23:53.521313: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.579820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.579919: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.584608: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.584732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.584778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.777889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.778017: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.778042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:23:53.778105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:23:53.778134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:24:13.557212: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:24:14.006013: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:24:15.230306: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8c0dc660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:24:15.230346: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:24:15.235756: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717961055.304693   27132 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:31:05,590] Trial 6 finished with value: 0.7559382319450378 and parameters: {'learning_rate': 0.001066547251479596, 'epsilon': 8.072100960180742e-06, 'maxlen': 128, 'batch_size': 16}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6426805257797241, 'accuracy': 0.7559382319450378, 'precision': 0.8022440671920776, 'recall': 0.6793349385261536, 'f1_score': 0.7356913427707532}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:31:06.008051: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.071792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.071910: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.077659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.077826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.077913: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.300008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.300166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.300185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:31:06.300284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:31:06.300313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:31:27.302566: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:31:27.818991: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:31:29.162443: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a78407450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:31:29.162483: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:31:29.168312: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717961489.237426   32462 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:39:10,053] Trial 7 finished with value: 0.7143705487251282 and parameters: {'learning_rate': 0.005253141961085814, 'epsilon': 5.926991098152858e-06, 'maxlen': 128, 'batch_size': 24}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.350872278213501, 'accuracy': 0.7143705487251282, 'precision': 0.6898002028465271, 'recall': 0.7790973782539368, 'f1_score': 0.7317345150151848}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:39:10.623733: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.683968: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.684086: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.689068: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.689439: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.689540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.876398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.876553: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.876572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:39:10.876642: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:39:10.876672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:39:50.011462: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:39:50.504175: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:39:51.887716: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a799ec9b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:39:51.887755: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:39:51.893019: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717961991.964075    5513 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:48:41,485] Trial 8 finished with value: 0.7701900005340576 and parameters: {'learning_rate': 0.001267287359835027, 'epsilon': 7.505472944349876e-06, 'maxlen': 448, 'batch_size': 32}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.0433777570724487, 'accuracy': 0.7701900005340576, 'precision': 0.7599999904632568, 'recall': 0.7897862195968628, 'f1_score': 0.7746068657280708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:48:42.088677: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.188900: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.189015: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.193491: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.193623: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.193700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.425358: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.425497: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.425514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:48:42.425582: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:48:42.425614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:49:11.276761: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:49:11.733494: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:49:13.181872: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a88be9640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:49:13.181914: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:49:13.187358: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717962553.271031   13038 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 16:54:55,409] Trial 9 finished with value: 0.7666270732879639 and parameters: {'learning_rate': 0.0030354317051018613, 'epsilon': 8.983487102148534e-07, 'maxlen': 256, 'batch_size': 40}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.9753907918930054, 'accuracy': 0.7666270732879639, 'precision': 0.7525309324264526, 'recall': 0.794536828994751, 'f1_score': 0.7729636098438346}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:54:55.923397: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.000796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.000898: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.005563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.005672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.005719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.199364: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.199504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.199524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 16:54:56.199586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 16:54:56.199618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 16:55:32.182124: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 16:55:32.696217: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 16:55:34.209368: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8ca514f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 16:55:34.209411: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 16:55:34.214745: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717962934.286960   18784 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:00:05,714] Trial 10 finished with value: 0.769002377986908 and parameters: {'learning_rate': 0.00014603820122935157, 'epsilon': 9.881746334515491e-06, 'maxlen': 384, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6281924843788147, 'accuracy': 0.769002377986908, 'precision': 0.7712574601173401, 'recall': 0.764845609664917, 'f1_score': 0.7680381530331553}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:00:06.320000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.404428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.404550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.431589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.431732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.431806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.635809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.635994: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.636013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:00:06.636082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:00:06.636137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:00:51.095493: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:00:51.581279: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:00:53.085382: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7da336c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:00:53.085429: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:00:53.091552: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717963253.171139   23310 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:07:00,612] Trial 11 finished with value: 0.7660332322120667 and parameters: {'learning_rate': 0.0028044958164182717, 'epsilon': 1.3100019667511034e-06, 'maxlen': 512, 'batch_size': 48}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.211718201637268, 'accuracy': 0.7660332322120667, 'precision': 0.7909091114997864, 'recall': 0.7232779264450073, 'f1_score': 0.7555831450630672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:07:01.170747: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.253042: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.253150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.259143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.259369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.259452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.487611: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.487753: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.487772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:07:01.487842: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:07:01.487875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:07:34.102872: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:07:34.620095: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:07:36.066976: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a701aa5d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:07:36.067057: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:07:36.073020: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717963656.151942   29132 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:14:00,470] Trial 12 finished with value: 0.7731591463088989 and parameters: {'learning_rate': 0.0032266059599009266, 'epsilon': 9.701854019422079e-08, 'maxlen': 320, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.2449067831039429, 'accuracy': 0.7731591463088989, 'precision': 0.759593665599823, 'recall': 0.7992874383926392, 'f1_score': 0.7789351909412756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:14:01.128410: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.206950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.207088: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.214469: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.214628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.214705: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.446377: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.446512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.446534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:14:01.446596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:14:01.446631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:14:44.918977: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:14:45.435708: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:14:47.051565: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8c201090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:14:47.051612: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:14:47.057116: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717964087.129756    1609 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:20:28,259] Trial 13 finished with value: 0.769002377986908 and parameters: {'learning_rate': 0.001295298580087127, 'epsilon': 7.281162634284743e-06, 'maxlen': 512, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6756192445755005, 'accuracy': 0.769002377986908, 'precision': 0.7738814949989319, 'recall': 0.7600950002670288, 'f1_score': 0.7669262951071172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:20:28.700523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:28.776245: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:28.776352: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:28.782520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:28.782740: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:28.782846: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:29.008832: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:29.009021: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:29.009046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:20:29.009122: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:20:29.009172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:20:53.340809: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:20:53.873426: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:20:55.294495: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a81b651f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:20:55.294537: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:20:55.300233: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717964455.373102    7061 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:23:55,570] Trial 14 finished with value: 0.7624703049659729 and parameters: {'learning_rate': 0.003993835942615503, 'epsilon': 7.015652824550597e-06, 'maxlen': 192, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.9118705987930298, 'accuracy': 0.7624703049659729, 'precision': 0.7721675038337708, 'recall': 0.7446556091308594, 'f1_score': 0.7581620533122767}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:23:56.160986: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.241579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.241716: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.247207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.247375: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.247454: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.481722: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.481939: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.481969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:23:56.482079: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:23:56.482119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:24:36.001143: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:24:36.507000: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:24:37.900467: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a88d5de00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:24:37.900510: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:24:37.905736: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717964677.976184   11092 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:32:31,185] Trial 15 finished with value: 0.6407363414764404 and parameters: {'learning_rate': 0.009837492301556172, 'epsilon': 3.6274459737970982e-06, 'maxlen': 448, 'batch_size': 24}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7117947340011597, 'accuracy': 0.6407363414764404, 'precision': 0.6643550395965576, 'recall': 0.5688835978507996, 'f1_score': 0.6129238473395351}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:32:31.790540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:31.852760: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:31.852866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:31.857150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:31.857263: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:31.857344: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:32.061564: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:32.061719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:32.061733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:32:32.061825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:32:32.061857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:33:15.873987: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:33:16.363557: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:33:17.810886: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a6d3fdf70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:33:17.810930: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:33:17.816361: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717965197.888991   19650 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:40:54,787] Trial 16 finished with value: 0.7743467688560486 and parameters: {'learning_rate': 0.00498254611734813, 'epsilon': 3.1725173263439506e-07, 'maxlen': 512, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.666378378868103, 'accuracy': 0.7743467688560486, 'precision': 0.7636986374855042, 'recall': 0.794536828994751, 'f1_score': 0.778812582293426}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:40:55.346087: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.420898: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.420999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.425609: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.425749: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.425798: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.615497: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.615625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.615647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:40:55.615709: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:40:55.615736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:41:33.108837: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:41:33.570845: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:41:34.935757: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a800ccc70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:41:34.935800: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:41:34.941254: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717965695.009783   25147 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 17:51:30,407] Trial 17 finished with value: 0.7476246953010559 and parameters: {'learning_rate': 0.004559364017041858, 'epsilon': 9.189320536511663e-06, 'maxlen': 448, 'batch_size': 16}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.0988969802856445, 'accuracy': 0.7476246953010559, 'precision': 0.7485101222991943, 'recall': 0.745843231678009, 'f1_score': 0.7471742972617564}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:51:31.040728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.104053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.104166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.109963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.110091: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.110139: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.323514: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.323658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.323672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 17:51:31.323741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 17:51:31.323775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 17:52:15.315903: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 17:52:15.830583: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 17:52:17.312453: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a95244450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 17:52:17.312502: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 17:52:17.323737: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717966337.403270    2400 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:03:04,979] Trial 18 finished with value: 0.6888360977172852 and parameters: {'learning_rate': 0.003762342999525968, 'epsilon': 3.7596041172755665e-06, 'maxlen': 512, 'batch_size': 16}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7855249047279358, 'accuracy': 0.6888360977172852, 'precision': 0.6698718070983887, 'recall': 0.7446556091308594, 'f1_score': 0.7052868581143108}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:03:05.622017: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.688500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.688609: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.696441: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.696621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.696706: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.928009: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.928460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.928493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:03:05.928742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:03:05.928821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:03:50.498332: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:03:50.998323: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:03:52.554763: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8c166bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:03:52.554806: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:03:52.560711: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717967032.635219   12618 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:09:18,144] Trial 19 finished with value: 0.7660332322120667 and parameters: {'learning_rate': 0.0036282048666224616, 'epsilon': 9.480129470492736e-06, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.2059497833251953, 'accuracy': 0.7660332322120667, 'precision': 0.7408602237701416, 'recall': 0.8182897567749023, 'f1_score': 0.777652361706911}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:09:18.718782: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:18.796219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:18.796358: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:18.804113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:18.804255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:18.804303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:19.005573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:19.005704: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:19.005722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:09:19.005808: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:09:19.005831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:10:00.966936: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:10:01.444349: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:10:02.823466: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7504de80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:10:02.823506: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:10:02.829027: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717967402.899637   17400 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:16:54,524] Trial 20 finished with value: 0.769002377986908 and parameters: {'learning_rate': 0.0004701980223818683, 'epsilon': 3.732155852204099e-06, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.0738201141357422, 'accuracy': 0.769002377986908, 'precision': 0.7570942044258118, 'recall': 0.7921615242958069, 'f1_score': 0.7742309909137512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:16:55.130674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.206856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.206959: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.213633: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.213790: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.213841: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.442553: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.442694: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.442727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:16:55.442798: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:16:55.442830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:17:37.032939: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:17:37.519541: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:17:38.966455: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8807ef70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:17:38.966498: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:17:38.972482: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717967859.042779   22337 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:27:40,946] Trial 21 finished with value: 0.7767220735549927 and parameters: {'learning_rate': 0.005721146348472081, 'epsilon': 5.960626742113069e-07, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.5851004123687744, 'accuracy': 0.7767220735549927, 'precision': 0.7566079497337341, 'recall': 0.815914511680603, 'f1_score': 0.7851428783858941}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:27:41.514244: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.603012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.603121: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.609588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.609918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.610073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.879789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.879930: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.879949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:27:41.880019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:27:41.880050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:28:19.202127: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:28:19.681162: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:28:21.172710: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8ccb94c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:28:21.172751: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:28:21.178577: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717968501.246700   27636 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:33:25,725] Trial 22 finished with value: 0.7695962190628052 and parameters: {'learning_rate': 0.007893925804039364, 'epsilon': 1.0345619845490056e-06, 'maxlen': 448, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7756505608558655, 'accuracy': 0.7695962190628052, 'precision': 0.7689573168754578, 'recall': 0.7707838416099548, 'f1_score': 0.7698694958811987}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:33:26.321319: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.402189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.402292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.408351: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.408475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.408540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.632592: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.632795: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.632814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:33:26.632886: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:33:26.632918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:34:04.590693: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:34:05.067972: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:34:06.508030: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a80300a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:34:06.508070: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:34:06.513455: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717968846.583638   32667 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:38:52,909] Trial 23 finished with value: 0.7678147554397583 and parameters: {'learning_rate': 0.004453316751062033, 'epsilon': 1.8636912461825685e-06, 'maxlen': 448, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6228970885276794, 'accuracy': 0.7678147554397583, 'precision': 0.7829360365867615, 'recall': 0.7410926222801208, 'f1_score': 0.7614399073874217}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:38:53.418442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.478040: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.478146: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.483843: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.483989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.484041: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.713818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.713950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.713968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:38:53.714028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:38:53.714062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:39:23.532946: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:39:23.983308: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:39:25.386336: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a98022950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:39:25.386377: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:39:25.392141: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717969165.460212    4984 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:43:30,836] Trial 24 finished with value: 0.7684085369110107 and parameters: {'learning_rate': 0.0014667785444628812, 'epsilon': 6.180668545028799e-06, 'maxlen': 320, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6329835057258606, 'accuracy': 0.7684085369110107, 'precision': 0.7749391794204712, 'recall': 0.7565320730209351, 'f1_score': 0.7656250065908983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:43:31.373047: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.444423: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.444522: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.450336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.450455: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.450501: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.659384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.659516: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.659533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:43:31.659603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:43:31.659630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:44:08.048286: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:44:08.521097: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:44:09.899275: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a800c6e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:44:09.899315: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:44:09.905279: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717969449.980300    9883 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 18:58:28,238] Trial 25 finished with value: 0.7684085369110107 and parameters: {'learning_rate': 0.00549261223807948, 'epsilon': 1.0840524972815255e-06, 'maxlen': 448, 'batch_size': 32}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.1455650329589844, 'accuracy': 0.7684085369110107, 'precision': 0.7646369934082031, 'recall': 0.775534451007843, 'f1_score': 0.7700471698174544}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:58:28.770168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:28.852326: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:28.852458: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:28.857926: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:28.858124: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:28.858224: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:29.097124: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:29.097308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:29.097329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 18:58:29.097417: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 18:58:29.097446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 18:59:02.245839: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 18:59:02.707100: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 18:59:04.022358: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a78091f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 18:59:04.022403: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 18:59:04.028373: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717970344.096691   17886 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:04:00,994] Trial 26 finished with value: 0.7642517685890198 and parameters: {'learning_rate': 0.0020623958720245796, 'epsilon': 9.788367247299544e-06, 'maxlen': 384, 'batch_size': 48}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.8034422993659973, 'accuracy': 0.7642517685890198, 'precision': 0.7690447568893433, 'recall': 0.7553443908691406, 'f1_score': 0.7621330082254312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:04:01.540309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.599129: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.599238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.605150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.605284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.605330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.834520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.834669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.834687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:04:01.834751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:04:01.834780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:04:42.523338: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:04:43.016386: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:04:44.498060: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a733ffbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:04:44.498147: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:04:44.504851: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717970684.583888   23440 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:14:49,941] Trial 27 finished with value: 0.7672209143638611 and parameters: {'learning_rate': 0.007988358202189965, 'epsilon': 3.38156282099931e-06, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.1330175399780273, 'accuracy': 0.7672209143638611, 'precision': 0.7522421479225159, 'recall': 0.7969121336936951, 'f1_score': 0.7739331095284334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:14:50.411038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.477005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.477126: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.492192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.492350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.492424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.704548: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.704679: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.704696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:14:50.704762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:14:50.704792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:15:14.392753: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:15:14.847675: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:15:16.126049: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7dc11950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:15:16.126089: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:15:16.131653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717971316.200412   28760 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:21:39,148] Trial 28 finished with value: 0.6680522561073303 and parameters: {'learning_rate': 0.006981544723402159, 'epsilon': 3.69832837428485e-07, 'maxlen': 192, 'batch_size': 16}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6240811347961426, 'accuracy': 0.6680522561073303, 'precision': 0.714719295501709, 'recall': 0.559382438659668, 'f1_score': 0.6275816314432976}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:21:39.787257: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:39.880762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:39.880924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:39.888090: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:39.888279: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:39.888357: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:40.105356: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:40.105487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:40.105509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:21:40.105578: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:21:40.105622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:22:21.149094: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:22:21.644934: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:22:23.030489: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8547e670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:22:23.030527: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:22:23.035924: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717971743.105233    2906 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:30:58,842] Trial 29 finished with value: 0.769002377986908 and parameters: {'learning_rate': 0.0031471418022183924, 'epsilon': 6.335243156879427e-07, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.1131535768508911, 'accuracy': 0.769002377986908, 'precision': 0.7699642181396484, 'recall': 0.7672209143638611, 'f1_score': 0.7685901183632581}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:30:59.321449: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.396729: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.396830: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.401652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.401774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.401820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.660810: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.660979: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.661002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:30:59.661075: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:30:59.661104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:31:26.812817: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:31:27.276292: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:31:28.661788: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a70135b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:31:28.661826: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:31:28.667538: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717972288.735950    8064 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:40:38,790] Trial 30 finished with value: 0.728622317314148 and parameters: {'learning_rate': 0.007486538430186897, 'epsilon': 9.119334092069123e-06, 'maxlen': 256, 'batch_size': 24}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6112481951713562, 'accuracy': 0.728622317314148, 'precision': 0.7054429054260254, 'recall': 0.7850356101989746, 'f1_score': 0.7431141018351871}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:40:39.353245: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.411866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.411963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.418093: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.418211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.418258: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.637836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.638057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.638100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:40:39.638180: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:40:39.638215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:41:18.444331: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:41:18.951027: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:41:20.333713: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8c144f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:41:20.333756: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:41:20.339446: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717972880.409097   15181 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:46:55,685] Trial 31 finished with value: 0.7553443908691406 and parameters: {'learning_rate': 0.005197047674086246, 'epsilon': 2.4901494346596094e-07, 'maxlen': 448, 'batch_size': 48}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.964088499546051, 'accuracy': 0.7553443908691406, 'precision': 0.770100474357605, 'recall': 0.7280284762382507, 'f1_score': 0.7484737207353613}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:46:56.349766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.429749: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.429854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.436660: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.436787: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.436834: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.707225: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.707382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.707406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:46:56.707490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:46:56.707524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:47:39.853181: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:47:40.340180: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:47:41.839924: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a78445ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:47:41.839965: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:47:41.845836: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717973261.914628   20871 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 19:56:47,571] Trial 32 finished with value: 0.7672209143638611 and parameters: {'learning_rate': 0.004785074717599181, 'epsilon': 1.999796621696045e-06, 'maxlen': 512, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.1667741537094116, 'accuracy': 0.7672209143638611, 'precision': 0.7353556752204895, 'recall': 0.834916889667511, 'f1_score': 0.7819800038323081}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:56:48.176872: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.238680: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.238783: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.243571: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.243719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.243796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.463215: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.463380: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.463401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 19:56:48.463470: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 19:56:48.463507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 19:57:31.139308: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 19:57:31.626904: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 19:57:33.065151: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6aa51f7650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 19:57:33.065193: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 19:57:33.070553: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717973853.139579   26556 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:02:52,393] Trial 33 finished with value: 0.7630641460418701 and parameters: {'learning_rate': 0.006219708585373239, 'epsilon': 9.150469545215925e-07, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6124545335769653, 'accuracy': 0.7630641460418701, 'precision': 0.7828863263130188, 'recall': 0.7280284762382507, 'f1_score': 0.7544615199361495}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:02:52.975285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.052884: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.052990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.059291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.059449: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.059504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.306951: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.307141: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.307166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:02:53.307398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:02:53.307461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:03:29.975052: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:03:30.443709: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:03:31.860714: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a88098680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:03:31.860760: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:03:31.866240: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717974211.936224   31391 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:08:14,378] Trial 34 finished with value: 0.66923987865448 and parameters: {'learning_rate': 0.009007240706898298, 'epsilon': 7.662981544318545e-06, 'maxlen': 384, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.697688102722168, 'accuracy': 0.66923987865448, 'precision': 0.6987447738647461, 'recall': 0.5950118899345398, 'f1_score': 0.6427197016449867}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:08:14.762302: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:14.825803: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:14.825909: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:14.829953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:14.830068: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:14.830115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:15.032519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:15.032674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:15.032692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:08:15.032804: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:08:15.032854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:08:32.362180: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:08:32.844651: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:08:34.084176: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7ea21480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:08:34.084217: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:08:34.089650: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717974514.158389    3802 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:12:52,899] Trial 35 finished with value: 0.754156768321991 and parameters: {'learning_rate': 0.00042064121926510805, 'epsilon': 1.1921234581595854e-06, 'maxlen': 64, 'batch_size': 16}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.6656860113143921, 'accuracy': 0.754156768321991, 'precision': 0.7311015129089355, 'recall': 0.8040379881858826, 'f1_score': 0.7658370971233942}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:12:53.322264: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.386271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.386378: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.391334: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.391497: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.391552: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.613708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.613867: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.613895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:12:53.613963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:12:53.614011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:13:15.235103: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:13:15.725600: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:13:17.169477: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a81217490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:13:17.169520: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:13:17.175191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717974797.246261    7000 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:15:54,227] Trial 36 finished with value: 0.679928719997406 and parameters: {'learning_rate': 0.009158712898192149, 'epsilon': 4.462330226807126e-06, 'maxlen': 128, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7414200901985168, 'accuracy': 0.679928719997406, 'precision': 0.7055630683898926, 'recall': 0.6175771951675415, 'f1_score': 0.658644699721391}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:15:54.857508: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:54.925734: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:54.925843: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:54.930465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:54.930601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:54.930651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:55.157456: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:55.157621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:55.157646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:15:55.157715: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:15:55.157741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:16:39.176880: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:16:39.660853: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:16:41.246887: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a808d11b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:16:41.246924: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:16:41.252334: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717975001.321681   11021 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:22:21,176] Trial 37 finished with value: 0.7577196955680847 and parameters: {'learning_rate': 0.005375555834936689, 'epsilon': 5.992707540041586e-07, 'maxlen': 512, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.9773291945457458, 'accuracy': 0.7577196955680847, 'precision': 0.7395143508911133, 'recall': 0.7957244515419006, 'f1_score': 0.7665903836427704}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:22:21.560217: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.622904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.623012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.627474: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.627594: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.627673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.872746: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.872893: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.872912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:22:21.872987: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:22:21.873019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:22:39.724635: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:22:40.201221: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:22:41.550554: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a836eb840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:22:41.550593: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:22:41.556234: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717975361.625987   16280 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:25:18,088] Trial 38 finished with value: 0.6401425004005432 and parameters: {'learning_rate': 0.008210296273174031, 'epsilon': 2.5062751183969364e-06, 'maxlen': 64, 'batch_size': 32}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7917636036872864, 'accuracy': 0.6401425004005432, 'precision': 0.6761193871498108, 'recall': 0.5380047559738159, 'f1_score': 0.59920634632444}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:25:18.827914: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:18.902839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:18.902946: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:18.908185: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:18.908340: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:18.908390: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:19.261214: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:19.261504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:19.261537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:25:19.261650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:25:19.261700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:26:03.730094: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:26:04.201353: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:26:05.539145: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a74fe99a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:26:05.539185: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:26:05.544287: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717975565.613687   19393 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:32:11,545] Trial 39 finished with value: 0.7707838416099548 and parameters: {'learning_rate': 0.002421283042846373, 'epsilon': 9.455938805348636e-06, 'maxlen': 512, 'batch_size': 48}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.2028542757034302, 'accuracy': 0.7707838416099548, 'precision': 0.8031914830207825, 'recall': 0.7173396944999695, 'f1_score': 0.757841919419955}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:32:12.112650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.171612: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.171709: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.178550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.178674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.178720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.380540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.380683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.380703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:32:12.380851: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:32:12.380938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:32:55.192471: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:32:55.704460: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:32:57.334460: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a6f487890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:32:57.334504: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:32:57.340699: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717975977.416126   25206 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:40:46,751] Trial 40 finished with value: 0.769002377986908 and parameters: {'learning_rate': 0.0028601944699542534, 'epsilon': 2.813230545789378e-07, 'maxlen': 512, 'batch_size': 48}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7928801774978638, 'accuracy': 0.769002377986908, 'precision': 0.7878018021583557, 'recall': 0.7363420724868774, 'f1_score': 0.761203218882739}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:40:47.178382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.250904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.251002: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.255693: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.255866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.255919: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.468732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.468882: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.468908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:40:47.468974: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:40:47.469003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:41:12.360092: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:41:12.893994: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:41:14.394003: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a94193be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:41:14.394043: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:41:14.400274: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717976474.481618   31334 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:44:12,516] Trial 41 finished with value: 0.7618764638900757 and parameters: {'learning_rate': 0.004238834350624649, 'epsilon': 3.328819923473548e-07, 'maxlen': 192, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.1223269701004028, 'accuracy': 0.7618764638900757, 'precision': 0.7549132704734802, 'recall': 0.775534451007843, 'f1_score': 0.765084936332901}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:44:13.017375: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.087108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.087224: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.091985: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.092120: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.092183: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.316956: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.317123: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.317146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:44:13.317237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:44:13.317305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:44:43.072633: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:44:43.529265: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:44:44.856322: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a755d32e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:44:44.856364: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:44:44.862081: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717976684.932573    2962 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:48:38,053] Trial 42 finished with value: 0.7701900005340576 and parameters: {'learning_rate': 0.0018426170118766099, 'epsilon': 1.3917232903315382e-06, 'maxlen': 320, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.0348842144012451, 'accuracy': 0.7701900005340576, 'precision': 0.7698695063591003, 'recall': 0.7707838416099548, 'f1_score': 0.7703264026681566}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:48:38.613994: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.695637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.695752: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.700505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.700652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.700700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.998318: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.998503: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.998528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:48:38.998608: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:48:38.998640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:49:12.349036: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:49:12.817721: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:49:14.276310: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a8c02da00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:49:14.276354: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:49:14.282644: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717976954.360479    7538 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:54:40,550] Trial 43 finished with value: 0.7618764638900757 and parameters: {'learning_rate': 0.003996726079369619, 'epsilon': 1.091897510168335e-08, 'maxlen': 320, 'batch_size': 56}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.152131199836731, 'accuracy': 0.7618764638900757, 'precision': 0.793608546257019, 'recall': 0.7078384757041931, 'f1_score': 0.7482737059275355}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:54:41.105486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.182721: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.182822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.187422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.187555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.187605: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.410727: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.410864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.410893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:54:41.410958: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:54:41.410990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 20:55:16.691963: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 20:55:17.155916: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 20:55:18.684467: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a733d1070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 20:55:18.684509: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 20:55:18.690204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717977318.766320   12485 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 20:59:41,496] Trial 44 finished with value: 0.7600950002670288 and parameters: {'learning_rate': 0.0034936918001447397, 'epsilon': 1.3014269429781545e-06, 'maxlen': 384, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 1.0894720554351807, 'accuracy': 0.7600950002670288, 'precision': 0.7155511975288391, 'recall': 0.8634204268455505, 'f1_score': 0.7825619040430629}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:59:42.094009: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.168113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.168214: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.172948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.173064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.173110: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.389638: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.389766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.389791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 20:59:42.389870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 20:59:42.389903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 21:00:22.781840: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 21:00:23.273058: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 21:00:24.583753: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a79a2fd70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 21:00:24.583791: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 21:00:24.589176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717977624.658245   16955 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 21:07:16,883] Trial 45 finished with value: 0.7684085369110107 and parameters: {'learning_rate': 0.00524525739404178, 'epsilon': 5.0894436418599e-07, 'maxlen': 512, 'batch_size': 64}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7510862350463867, 'accuracy': 0.7684085369110107, 'precision': 0.7591742873191833, 'recall': 0.786223292350769, 'f1_score': 0.77246207124462}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:07:17.397377: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.472657: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.472753: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.477247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.477368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.477415: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.708497: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.708650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.708678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 21:07:17.708744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:07:17.708775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 21:07:53.919471: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 21:07:54.382180: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 21:07:55.706723: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a701ae1e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 21:07:55.706764: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 21:07:55.712421: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717978075.783997   21894 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 21:14:00,940] Trial 46 finished with value: 0.7743467688560486 and parameters: {'learning_rate': 0.0005803571577037382, 'epsilon': 1.0832850567238331e-06, 'maxlen': 384, 'batch_size': 32}. Best is trial 0 with value: 0.7767220735549927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.8773791193962097, 'accuracy': 0.7743467688560486, 'precision': 0.7796609997749329, 'recall': 0.764845609664917, 'f1_score': 0.7721822477937939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:14:01.453382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.512796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.512904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.517537: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.517667: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.517716: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.739778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.739932: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.739954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 21:14:01.740027: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:14:01.740052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 21:14:32.948343: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 21:14:33.411708: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 21:14:34.922886: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7c82a180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 21:14:34.922926: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 21:14:34.928467: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717978475.027235   28967 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 21:23:01,118] Trial 47 finished with value: 0.7773159146308899 and parameters: {'learning_rate': 0.00134290641180543, 'epsilon': 9.286242488066606e-07, 'maxlen': 320, 'batch_size': 24}. Best is trial 47 with value: 0.7773159146308899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.7497057914733887, 'accuracy': 0.7773159146308899, 'precision': 0.7803121209144592, 'recall': 0.7719715237617493, 'f1_score': 0.776119414847984}\n",
      "Trial 47 achieved value: 0.7773159146308899 with  0.0764% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:23:01.690910: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:01.772098: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:01.772212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:01.778786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:01.778992: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:01.779125: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:02.020809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:02.021005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:02.021037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 21:23:02.021113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:23:02.021142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 21:23:33.043007: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 21:23:33.495426: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 21:23:34.857236: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a7d08c590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 21:23:34.857299: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 21:23:34.862599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717979014.930835    4341 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 21:31:56,414] Trial 48 finished with value: 0.7571259140968323 and parameters: {'learning_rate': 0.003299067536459603, 'epsilon': 8.895018802894939e-07, 'maxlen': 320, 'batch_size': 16}. Best is trial 47 with value: 0.7773159146308899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.9283168315887451, 'accuracy': 0.7571259140968323, 'precision': 0.777208685874939, 'recall': 0.7209026217460632, 'f1_score': 0.747997530545041}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:31:56.887657: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:56.946315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:56.946458: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:56.951546: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:56.951749: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:56.951828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:57.184776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:57.184917: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:57.184939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 21:31:57.185004: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 21:31:57.185036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-06-09 21:32:25.109301: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_38/output/_24'\n",
      "2024-06-09 21:32:25.597664: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-09 21:32:26.894914: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6a78576a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-09 21:32:26.894958: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-06-09 21:32:26.900551: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717979546.970520   12862 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2024-06-09 21:44:17,876] Trial 49 finished with value: 0.7660332322120667 and parameters: {'learning_rate': 0.002377209129320961, 'epsilon': 3.963945054132867e-06, 'maxlen': 256, 'batch_size': 16}. Best is trial 47 with value: 0.7773159146308899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'loss': 0.8179202675819397, 'accuracy': 0.7660332322120667, 'precision': 0.7698795199394226, 'recall': 0.7589073777198792, 'f1_score': 0.7643540751585819}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"LSTM_MODEL_PARA_AUG_CBOW\"):\n",
    "    # Initialize the Optuna study\n",
    "    pruner = optuna.pruners.HyperbandPruner(min_resource=2, max_resource=20, reduction_factor=3)\n",
    "    sampler=optuna.samplers.TPESampler(multivariate=True)\n",
    "    study_name = \"LSTM_MODEL_PARA_AUG_CBOW_V10\"  # Unique identifier of the study.\n",
    "    storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        pruner=pruner,\n",
    "        sampler=sampler,\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    # Execute the hyperparameter optimization trials.\n",
    "    # Note the addition of the `champion_callback` inclusion to control our logging\n",
    "    complete_trials = 0\n",
    "    while complete_trials < 50:\n",
    "        study.optimize(lambda x: objective(x, study), n_trials=1, callbacks=[champion_callback])\n",
    "        complete_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_accuracy\", study.best_value)\n",
    "\n",
    "    # Log tags\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"FAKE_NEWS\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"LSTM\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d520c-3ea4-4d98-a20c-de1872e7c401",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def pad_split(x):\n",
    "        x += ((384 - len(x)) if len(x)<384 else 0) * [0]    \n",
    "        return x[:384]\n",
    "tf.keras.utils.set_random_seed(5113)\n",
    "model = get_model(0.0017086058268768625, 6.372071470083102e-6, 384)\n",
    "train_lstm = train['train_token'].apply(lambda x: pad_split(x))\n",
    "validate_lstm = validate['train_token'].apply(lambda x: pad_split(x))\n",
    "history=model.fit(list(train_lstm.values), [float(x) for x in train[\"misinformation\"].values],validation_data=(list(validate_lstm.values), [float(x) for x in validate[\"misinformation\"].values]), epochs=2,batch_size=24,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd56383-eb3a-40cc-bc45-17a96986147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "import nltk.data\n",
    "import itertools\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/PY3/portuguese.pickle')\n",
    "class FakeTokenizer:\n",
    "    def __init__(self, all_training_words, train, maxlen, sent_tokenizer):\n",
    "        self.sent_tokenizer = sent_tokenizer\n",
    "        self.T_VOCAB = sorted(list(all_training_words))\n",
    "        self.tokenizer = Tokenizer(num_words=len(T_VOCAB), char_level=False)\n",
    "        self.tokenizer.fit_on_texts(list(train[\"tokens\"].values))\n",
    "        self.maxlen = maxlen\n",
    "    def pad_split(self, x):\n",
    "        x += ((self.maxlen - len(x)) if len(x)<self.maxlen else 0) * [0]    \n",
    "        return x[:self.maxlen]\n",
    "    def text_tokenizer(self, text):\n",
    "        tokenized_text = self.sent_tokenizer.tokenize(text)\n",
    "        tokenized_text = self.tokenizer.texts_to_sequences(tokenized_text)\n",
    "        tokenized_text = list(itertools.chain.from_iterable(tokenized_text))\n",
    "        return self.pad_split(tokenized_text)\n",
    "    \n",
    "with open('fake_full_aug_tokenizer_lstm.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(FakeTokenizer(all_training_words, train, 448, sent_tokenizer), f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72725540-3729-4628-9f20-83a0d17fa655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('lstm_model_best.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babf199b-5ccb-45c7-bf0f-101986f5f5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 06:39:36.574043: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.609797: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.609857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.614363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.614521: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.614570: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.767774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.767881: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.767893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-01 06:39:36.767948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 06:39:36.767969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4080 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-07-01 06:39:37.645848: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 265072800 exceeds 10% of free system memory.\n",
      "2024-07-01 06:39:40.597253: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 265072800 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(0.002047955269692605, 1.985084871786947e-06, 448)\n",
    "model.load_weights('best_lstm_0.79038006067276.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a15e59-d17c-45d6-8a0e-ab515ccfe6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3722</td>\n",
       "      <td>O PT convocou todos os macumbeiros do Brasil e...</td>\n",
       "      <td>1</td>\n",
       "      <td>3722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16059</td>\n",
       "      <td>“Bem, acredito que esteje tudo bem com você, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>16059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13247</td>\n",
       "      <td>“Laudo médico rompimento da artéria devido o e...</td>\n",
       "      <td>1</td>\n",
       "      <td>13247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11255</td>\n",
       "      <td>… Já está sendo vendida em outros Estados e es...</td>\n",
       "      <td>1</td>\n",
       "      <td>11255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15979</td>\n",
       "      <td>Na Argentina ta tudo normal! STF da Argentina ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>6283</td>\n",
       "      <td>￼\\n\\nGeneral Paulo Chagas alerta Ciro Gomes\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>6283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>6707</td>\n",
       "      <td>moradores da cidade argentina santiago del est...</td>\n",
       "      <td>0</td>\n",
       "      <td>6707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>4081</td>\n",
       "      <td>Montes claros parou pra gritar 17.\\nÉ só o com...</td>\n",
       "      <td>0</td>\n",
       "      <td>4081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>14727</td>\n",
       "      <td>A atriz da Globo teve um vídeo vazado na inter...</td>\n",
       "      <td>0</td>\n",
       "      <td>14727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>12575</td>\n",
       "      <td>Lançada nesta terça-feira (29) no Brasil com 5...</td>\n",
       "      <td>0</td>\n",
       "      <td>12575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0           3722  O PT convocou todos os macumbeiros do Brasil e...   \n",
       "1          16059  “Bem, acredito que esteje tudo bem com você, a...   \n",
       "2          13247  “Laudo médico rompimento da artéria devido o e...   \n",
       "3          11255  … Já está sendo vendida em outros Estados e es...   \n",
       "4          15979  Na Argentina ta tudo normal! STF da Argentina ...   \n",
       "...          ...                                                ...   \n",
       "1679        6283  ￼\\n\\nGeneral Paulo Chagas alerta Ciro Gomes\\n\\...   \n",
       "1680        6707  moradores da cidade argentina santiago del est...   \n",
       "1681        4081  Montes claros parou pra gritar 17.\\nÉ só o com...   \n",
       "1682       14727  A atriz da Globo teve um vídeo vazado na inter...   \n",
       "1683       12575  Lançada nesta terça-feira (29) no Brasil com 5...   \n",
       "\n",
       "      misinformation  index  \n",
       "0                  1   3722  \n",
       "1                  1  16059  \n",
       "2                  1  13247  \n",
       "3                  1  11255  \n",
       "4                  1  15979  \n",
       "...              ...    ...  \n",
       "1679               0   6283  \n",
       "1680               0   6707  \n",
       "1681               0   4081  \n",
       "1682               0  14727  \n",
       "1683               0  12575  \n",
       "\n",
       "[1684 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"fake_test_balanced_indexed.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04f1e03b-e3bd-495e-a9c4-a8c2f2e5a454",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "z1p1DWoAJump",
    "outputId": "2f81ae69-a566-4890-fa8b-0222e741bd44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 06:40:33.899582: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "from transformers import pipeline\n",
    "def classifier(text, model, tokenizer):\n",
    "    return model.predict([tokenizer(text)], verbose=0)\n",
    "#classifier = pipeline(task=\"text-classification\", model=model, top_k=None, tokenizer=FakeTokenizer(all_training_words, train, 1200).tokenizer)\n",
    "fake_tokenizer = FakeTokenizer(all_training_words, train, 448, sent_tokenizer)\n",
    "classify_all = test[\"text\"].apply(lambda x: classifier(x, model, fake_tokenizer.text_tokenizer)).values\n",
    "\n",
    "pred_labels = []\n",
    "for classification in classify_all:\n",
    "  if classification[0] >= 0.5:\n",
    "    pred_labels.append(1)\n",
    "  else:\n",
    "    pred_labels.append(0)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(test[\"misinformation\"].values, pred_labels)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Não Fake News\", \"Fake News\"])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206ac24d-38ec-482a-89be-206a9d852746",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "2jkMALsgc9Bj",
    "outputId": "09cea994-d3d2-42bf-d7cc-23d5a88e42e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#old_test = pd.read_csv(\"drive/MyDrive/test_fake.csv\")\n",
    "##classifier = pipeline(task=\"text-classification\", model=model, top_k=None, tokenizer=tokenizer)\n",
    "#classify_all_old = classifier(list(old_test[\"text\"].values))\n",
    "#\n",
    "#pred_labels = []\n",
    "#for classification in classify_all_old:\n",
    "#  label0 = 0\n",
    "#  label1 = 0\n",
    "#  for label in classification:\n",
    "#    if label[\"label\"] == \"LABEL_0\":\n",
    "#      label0=label[\"score\"]\n",
    "#    if label[\"label\"] == \"LABEL_1\":\n",
    "#      label1=label[\"score\"]\n",
    "#  if label0 > label1:\n",
    "#    pred_labels.append(0)\n",
    "#  else:\n",
    "#    pred_labels.append(1)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(test[\"misinformation\"].values, pred_labels)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Não Fake News\", \"Fake News\"])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.savefig('lstm_results.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e73d119-6b0b-4c5a-8e4a-51b770077325",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMqhIC2L-nDz",
    "outputId": "12b09ff9-1b69-4c30-8988-ce4110f44007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       842\n",
      "           1       0.78      0.74      0.76       842\n",
      "\n",
      "    accuracy                           0.77      1684\n",
      "   macro avg       0.77      0.77      0.77      1684\n",
      "weighted avg       0.77      0.77      0.77      1684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"0\", \"1\"]\n",
    "print(classification_report(test[\"misinformation\"].map(lambda x: str(x)).values, [ str(x) for x in pred_labels], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a476d638-f6e8-4316-8ad8-ba98e75d9576",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_BCF_RLAOVR",
    "outputId": "8398d898-3387-4896-97a7-8c4992485e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75426621, 0.77763975]),\n",
       " array([0.78741093, 0.74346793]),\n",
       " array([0.77048228, 0.76017001]),\n",
       " array([842, 842]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(test[\"misinformation\"].values, pred_labels, average=None, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35627b2f-d507-4a69-a026-52b87e982888",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WhVwxg26Rx8",
    "outputId": "b13bbfed-a4d2-40cd-fbf4-c21f25b2388c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7654394299287411"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test[\"misinformation\"].values, pred_labels, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea3184dc-1285-450a-be5b-4ee9a70f422a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "editable": true,
    "id": "eVSrC3Ru0P0A",
    "outputId": "7dded4b7-62a9-448d-e609-0d248fc6626a",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7593773-cd57-4ef5-8476-94c746ed805d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
